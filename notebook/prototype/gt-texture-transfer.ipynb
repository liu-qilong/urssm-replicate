{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cd64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c810c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f2724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848513d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from src.infra import config\n",
    "\n",
    "path = '../../config/vec.yaml'\n",
    "opt = config.load_config(path)\n",
    "opt.path = path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136a710",
   "metadata": {},
   "source": [
    "## Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9128a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_root = Path('/home/knpob/Documents/Hinton/data/shape-corr/FAUST_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8675d402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset.shape_cor_fast import PairFaustDatasetFast\n",
    "\n",
    "dataset = PairFaustDatasetFast(\n",
    "    data_root=data_root,\n",
    "    phase='train',\n",
    "    return_faces=True,\n",
    "    return_L=True,\n",
    "    return_mass=True,\n",
    "    num_evecs=200,\n",
    "    return_evecs=True,\n",
    "    return_grad=True,\n",
    "    return_corr=True,\n",
    "    return_dist=True,\n",
    ")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55d6e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataloader.shape_cor_batch import BatchShapePairDataLoader\n",
    "\n",
    "dataloader = BatchShapePairDataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae47d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000',\n",
       "  'tr_reg_000'],\n",
       " ['tr_reg_008',\n",
       "  'tr_reg_009',\n",
       "  'tr_reg_010',\n",
       "  'tr_reg_011',\n",
       "  'tr_reg_012',\n",
       "  'tr_reg_013',\n",
       "  'tr_reg_014',\n",
       "  'tr_reg_015'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.tensor import to_device\n",
    "\n",
    "for idx, data in enumerate(dataloader):\n",
    "    data = to_device(data, device)\n",
    "    if idx == 1:\n",
    "        break\n",
    "\n",
    "data['first']['name'], data['second']['name'], "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dab3a4",
   "metadata": {},
   "source": [
    "## Create point-to-point maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3d9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 5001]),\n",
       " tensor([[   0,   28,    2,  ...,   -1,   -1,   -1],\n",
       "         [   0, 2383,   96,  ...,   -1,   -1,   -1],\n",
       "         [   0,   28,    2,  ..., 1949,   -1,   -1],\n",
       "         ...,\n",
       "         [  71,   16,    2,  ...,   -1,   -1,   -1],\n",
       "         [   0,    1,  118,  ..., 1949,   -1,   -1],\n",
       "         [  70,   28,  118,  ...,   -1,   -1,   -1]], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.fmap import corr2pointmap_vectorized\n",
    "\n",
    "p2p = corr2pointmap_vectorized(\n",
    "    data['first']['corr'],\n",
    "    data['second']['corr'],\n",
    "    max(data['second']['num_verts']),\n",
    ")\n",
    "p2p.shape, p2p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5e5d3",
   "metadata": {},
   "source": [
    "### Missing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89146ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0,  ..., 7, 7, 7], device='cuda:0'),\n",
       " tensor([   4,   18,   35,  ..., 4998, 4999, 5000], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_no_corr, vtx_no_corr = torch.where(p2p == -1)\n",
    "batch_no_corr, vtx_no_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac369eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B, V, _ = data['second']['verts'].shape\n",
    "\n",
    "corr_miss = torch.ones((V, V))\n",
    "corr_miss[batch_no_corr, vtx_no_corr] = 0\n",
    "corr_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ee827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('html')\n",
    "\n",
    "idx = 0\n",
    "\n",
    "name_x, name_y = data['first']['name'], data['second']['name']\n",
    "verts_num_x = data['first']['num_verts']\n",
    "verts_num_y = data['second']['num_verts']\n",
    "faces_num_x = data['first']['num_faces']\n",
    "faces_num_y = data['second']['num_faces']\n",
    "\n",
    "output_path = Path('output/gt-texture-transfer/missing')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx in range(B):\n",
    "    mesh_y = pv.read(data_root / 'off' / f'{name_y[idx]}.off')\n",
    "    mesh_y['missing'] = corr_miss[idx, :verts_num_y[idx]].cpu().numpy()\n",
    "    \n",
    "    pl = pv.Plotter(off_screen=True)\n",
    "    pl.add_mesh(\n",
    "        mesh=mesh_y,\n",
    "        scalars='missing',\n",
    "    )\n",
    "    pl.camera_position = 'xy'\n",
    "    pl.screenshot(output_path / f'{idx}', window_size=[1024, 1024], return_img=False)\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f86fe",
   "metadata": {},
   "source": [
    "### Single incomplete map filling\n",
    "\n",
    "Treat the incomplete ground-truth map as a set of incomplete correspondences labeling. Then construct corresponding point-indicator functions for functional maps solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42f57153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([   0,    1,    2,  ..., 4994, 4995, 4997], device='cuda:0'),),\n",
       " tensor([   0, 2383,   96,  ..., 4997, 2760, 1949], device='cuda:0'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "vtx_y_ls = torch.where(p2p[idx] != -1)\n",
    "vtx_x_ls = p2p[idx][vtx_y_ls]\n",
    "vtx_y_ls, vtx_x_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6c9b840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4999, 3503]), torch.Size([5001, 3503]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, V_x, _ = data['first']['verts'].shape\n",
    "_, V_y, _ = data['second']['verts'].shape\n",
    "\n",
    "delta_x = torch.eye(V_x, V_x).to(device=p2p.device)\n",
    "delta_y = torch.eye(V_y, V_y).to(device=p2p.device)\n",
    "\n",
    "feat_x = delta_x[vtx_x_ls].T # [V, C]\n",
    "feat_y = delta_y[vtx_y_ls].T # [V, C]\n",
    "feat_x.shape, feat_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "150e9f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.7579e-01,  3.0815e-05,  4.0791e-06,  ...,  5.5985e-08,\n",
       "          -4.2601e-08,  1.0078e-07],\n",
       "         [-6.3886e-06,  4.3833e-01, -1.6123e-04,  ...,  8.7883e-08,\n",
       "           6.0843e-08, -3.3812e-08],\n",
       "         [-4.0919e-06,  4.3851e-04,  8.6647e-01,  ...,  1.0924e-08,\n",
       "          -8.6053e-09,  9.2009e-10],\n",
       "         ...,\n",
       "         [ 2.8654e-08, -1.5024e-08,  9.5501e-08,  ...,  1.3947e-01,\n",
       "          -1.3023e-01,  6.2209e-03],\n",
       "         [-6.8533e-08, -8.2695e-08,  2.4661e-08,  ..., -3.5313e-02,\n",
       "           1.8958e-01,  3.3373e-02],\n",
       "         [ 5.1464e-08,  7.2539e-08, -4.6112e-09,  ...,  1.2346e-01,\n",
       "           6.5107e-02,  5.3503e-02]]], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.module.fmap import RegularizedFMNet_vectorized\n",
    "\n",
    "fmap_solver = RegularizedFMNet_vectorized()\n",
    "Cxy = fmap_solver(\n",
    "    feat_x=feat_x.unsqueeze(0),\n",
    "    feat_y=feat_y.unsqueeze(0),\n",
    "    evals_x=data['first']['evals'][idx].unsqueeze(0),\n",
    "    evals_y=data['second']['evals'][idx].unsqueeze(0),\n",
    "    evecs_trans_x=data['first']['evecs_trans'][idx].unsqueeze(0),\n",
    "    evecs_trans_y=data['second']['evecs_trans'][idx].unsqueeze(0),\n",
    ")[0]\n",
    "Cxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc7f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,   16,  145,  ..., 1908, 1908, 3540]], device='cuda:0'),\n",
       " tensor(0, device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.fmap import fmap2pointmap_vectorized\n",
    "\n",
    "evecs_x = data['first']['evecs'][idx].unsqueeze(0)  # [1, V_y, k]\n",
    "evecs_y = data['second']['evecs'][idx].unsqueeze(0)  # [1, V_y, k]\n",
    "\n",
    "p2p_fill = fmap2pointmap_vectorized(\n",
    "    Cxy=Cxy,\n",
    "    evecs_x=evecs_x,\n",
    "    evecs_y=evecs_y,\n",
    "    verts_mask_x=torch.ones((1, V_x), dtype=torch.bool, device=device),\n",
    "    verts_mask_y=torch.ones((1, V_y), dtype=torch.bool, device=device),\n",
    ")\n",
    "p2p_fill, (p2p_fill == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfce9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,   16,  145,  ..., 1908, 1908, 3540]], device='cuda:0'),\n",
       " tensor(0, device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2p_fill, (p2p_fill == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.fmap import pointmap2Pyx_smooth_vectorized, pointmap2Pyx_vectorized\n",
    "\n",
    "evecs_trans_x = data['first']['evecs_trans'][idx].unsqueeze(0)  # [1, V_x, k]\n",
    "evecs_trans_y = data['second']['evecs_trans'][idx].unsqueeze(0)  # [1, V_y, k]\n",
    "\n",
    "Pyx_fill = pointmap2Pyx_smooth_vectorized(\n",
    "    p2p=p2p_fill,\n",
    "    evecs_x=evecs_x,\n",
    "    evecs_y=evecs_y,\n",
    "    evecs_trans_x=evecs_trans_x,\n",
    "    evecs_trans_y=evecs_trans_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad323d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000]],\n",
       "        device='cuda:0'),\n",
       " tensor([[1.2589, 1.2118, 1.4185,  ..., 0.7747, 1.4900, 1.8969]],\n",
       "        device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pyx_fill.sum(axis=-1), Pyx_fill.sum(axis=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ef7a6",
   "metadata": {},
   "source": [
    "Validate that padding zero-channels to `feat_x` `feat_y` does not change the functional map solver output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8da680",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 5000\n",
    "feat_x_ = torch.zeros((V_x, V), device=feat_x.device)\n",
    "feat_y_ = torch.zeros((V_y, V), device=feat_y.device)\n",
    "feat_x_[:feat_x.shape[0], :feat_x.shape[1]] = feat_x\n",
    "feat_y_[:feat_y.shape[0], :feat_y.shape[1]] = feat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98a0e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.7579e-01,  3.0815e-05,  4.0791e-06,  ...,  5.5985e-08,\n",
       "          -4.2601e-08,  1.0078e-07],\n",
       "         [-6.3886e-06,  4.3833e-01, -1.6122e-04,  ...,  8.7883e-08,\n",
       "           6.0843e-08, -3.3812e-08],\n",
       "         [-4.0920e-06,  4.3851e-04,  8.6647e-01,  ...,  1.0924e-08,\n",
       "          -8.6053e-09,  9.2007e-10],\n",
       "         ...,\n",
       "         [ 2.8654e-08, -1.5024e-08,  9.5501e-08,  ...,  1.3947e-01,\n",
       "          -1.3023e-01,  6.2209e-03],\n",
       "         [-6.8533e-08, -8.2695e-08,  2.4661e-08,  ..., -3.5313e-02,\n",
       "           1.8958e-01,  3.3373e-02],\n",
       "         [ 5.1464e-08,  7.2539e-08, -4.6112e-09,  ...,  1.2346e-01,\n",
       "           6.5107e-02,  5.3503e-02]]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.module.fmap import RegularizedFMNet_vectorized\n",
    "\n",
    "fmap_solver = RegularizedFMNet_vectorized()\n",
    "Cxy_ = fmap_solver(\n",
    "    feat_x=feat_x_.unsqueeze(0),\n",
    "    feat_y=feat_y_.unsqueeze(0),\n",
    "    evals_x=data['first']['evals'][idx].unsqueeze(0),\n",
    "    evals_y=data['second']['evals'][idx].unsqueeze(0),\n",
    "    evecs_trans_x=data['first']['evecs_trans'][idx].unsqueeze(0),\n",
    "    evecs_trans_y=data['second']['evecs_trans'][idx].unsqueeze(0),\n",
    ")[0]\n",
    "Cxy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41d6f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9954e-07, device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Cxy - Cxy_).norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971e43a",
   "metadata": {},
   "source": [
    "### Batched incomplete maps filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80bbc353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4999, 5001, 5000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, V_x, _ = data['first']['verts'].shape\n",
    "_, V_y, _ = data['second']['verts'].shape\n",
    "_, V_t = data['first']['corr'].shape\n",
    "B, V_x, V_y, V_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54fddf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4999, 4999]), torch.Size([8, 5001, 5001]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_x = torch.eye(V_x, V_x).repeat(B, 1, 1).to(device=p2p.device) # [B, V_x, V_x]\n",
    "delta_y = torch.eye(V_y, V_y).repeat(B, 1, 1).to(device=p2p.device) # [B, V_x, V_x]\n",
    "delta_x.shape, delta_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25d87dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4999, 5000]), torch.Size([8, 5001, 5000]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_x = data['first']['corr']  # [B, V_t]\n",
    "corr_y = data['second']['corr']  # [B, V_t]\n",
    "batch_idx = torch.arange(B, device=corr_y.device).unsqueeze(1).expand(B, V_t)  # [B, V_t]\n",
    "\n",
    "feat_x = delta_x[batch_idx, corr_x].transpose(1, 2)  # [B, V_t, V_x] -> [B, V_x, V_t]\n",
    "feat_y = delta_y[batch_idx, corr_y].transpose(1, 2)  # [B, V_t, V_y] -> [B, V_y, V_t]\n",
    "\n",
    "feat_x.shape, feat_y.shape # p.s. now we get V_t channels of corresponding point indicator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71f31728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 200, 200])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.module.fmap import RegularizedFMNet_vectorized\n",
    "\n",
    "fmap_solver = RegularizedFMNet_vectorized()\n",
    "Cxy, _ = fmap_solver(\n",
    "    feat_x=feat_x,\n",
    "    feat_y=feat_y,\n",
    "    evals_x=data['first']['evals'],\n",
    "    evals_y=data['second']['evals'],\n",
    "    evecs_trans_x=data['first']['evecs_trans'],\n",
    "    evecs_trans_y=data['second']['evecs_trans'],\n",
    ")\n",
    "Cxy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1475298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 109,    1,    2,  ..., 1945, 1945,   -1],\n",
       "         [   0,   16,  145,  ..., 1908, 1908,   -1],\n",
       "         [  16, 2383,    6,  ..., 2001, 2001,   -1],\n",
       "         ...,\n",
       "         [2383, 2383,  107,  ..., 4322, 4322,   -1],\n",
       "         [  20, 2383,    6,  ..., 2101, 2101, 2101],\n",
       "         [  16, 2383,  107,  ..., 4629, 4629,   -1]], device='cuda:0'),\n",
       " tensor(9, device='cuda:0'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.fmap import fmap2pointmap_vectorized\n",
    "\n",
    "p2p_fill = fmap2pointmap_vectorized(\n",
    "    Cxy=Cxy,\n",
    "    evecs_x=data['first']['evecs'],\n",
    "    evecs_y=data['second']['evecs'],\n",
    "    verts_mask_x=data['first']['verts_mask'],\n",
    "    verts_mask_y=data['second']['verts_mask'],\n",
    ")\n",
    "p2p_fill, (p2p_fill == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed722437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.0000]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0.8896, 0.8124, 1.2605,  ..., 0.2357, 0.7723, 1.6971],\n",
       "         [1.2698, 1.2414, 1.4175,  ..., 0.7900, 1.4760, 1.7978],\n",
       "         [1.2106, 1.1001, 1.7506,  ..., 1.4366, 1.2905, 1.2460],\n",
       "         ...,\n",
       "         [1.7351, 1.8086, 1.3986,  ..., 0.6672, 1.2421, 0.1283],\n",
       "         [0.9146, 0.7839, 1.5355,  ..., 1.2225, 1.5520, 2.0346],\n",
       "         [1.4698, 1.4486, 1.7543,  ..., 2.7880, 1.7022, 0.8091]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pyx_fill = pointmap2Pyx_smooth_vectorized(\n",
    "    p2p=p2p_fill,\n",
    "    evecs_x=data['first']['evecs'],\n",
    "    evecs_y=data['second']['evecs'],\n",
    "    evecs_trans_x=data['first']['evecs_trans'],\n",
    "    evecs_trans_y=data['second']['evecs_trans'],\n",
    ")\n",
    "\n",
    "Pyx_fill.sum(axis=-1), Pyx_fill.sum(axis=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ead3a",
   "metadata": {},
   "source": [
    "## Texture transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dda8ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('html')\n",
    "\n",
    "from src.utils.fmap import pointmap2Pyx_vectorized, pointmap2Pyx_smooth_vectorized\n",
    "from src.utils.texture import write_obj_pair\n",
    "from src.utils.tensor import to_numpy\n",
    "\n",
    "output_path = Path('output/gt-texture-transfer')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Pyx = pointmap2Pyx_smooth_vectorized(\n",
    "    p2p=p2p_fill,\n",
    "    evecs_x = data['first']['evecs'],\n",
    "    evecs_y = data['second']['evecs'],\n",
    "    evecs_trans_x = data['first']['evecs_trans'],\n",
    "    evecs_trans_y = data['second']['evecs_trans'],\n",
    ")\n",
    "\n",
    "# Pyx = pointmap2Pyx_vectorized(\n",
    "#     p2p=p2p_fill,\n",
    "#     num_verts_x = data['first']['num_verts'],\n",
    "#     num_verts_y = data['second']['num_verts'],\n",
    "# )\n",
    "\n",
    "name_x, name_y = data['first']['name'], data['second']['name']\n",
    "verts_num_x = data['first']['num_verts']\n",
    "verts_num_y = data['second']['num_verts']\n",
    "faces_num_x = data['first']['num_faces']\n",
    "faces_num_y = data['second']['num_faces']\n",
    "\n",
    "for idx in range(len(data['first']['name'])):\n",
    "    # export mesh w/ texture\n",
    "    write_obj_pair(\n",
    "        file_name1=str(output_path / f'{name_x[idx]}.obj'),\n",
    "        file_name2=str(output_path / f'{name_x[idx]}--{name_y[idx]}.obj'),\n",
    "        faces1=to_numpy(data['first']['faces'][idx, :faces_num_x[idx]]),\n",
    "        verts1=to_numpy(data['first']['verts'][idx, :verts_num_x[idx]]),\n",
    "        verts2=to_numpy(data['second']['verts'][idx, :verts_num_y[idx]]),\n",
    "        faces2=to_numpy(data['second']['faces'][idx, :faces_num_y[idx]]),\n",
    "        Pyx=to_numpy(Pyx[idx, :verts_num_y[idx], :verts_num_x[idx]]),\n",
    "        texture_file=str(output_path / 'texture.png'),\n",
    "    )\n",
    "\n",
    "    # render texture transfer\n",
    "    pl = pv.Plotter(off_screen=True)\n",
    "    pl.add_mesh(\n",
    "        mesh=pv.read(output_path / f'{name_x[idx]}.obj'),\n",
    "        texture=pv.read_texture(output_path / 'texture.png'),\n",
    "    )\n",
    "    pl.add_mesh(\n",
    "        mesh=pv.read(output_path / f'{name_x[idx]}--{name_y[idx]}.obj').translate([1, 0, 0]),\n",
    "        texture=pv.read_texture(output_path / 'texture.png'),\n",
    "    )\n",
    "    pl.camera_position = 'xy'\n",
    "    pl.screenshot(output_path / f'{idx}', window_size=[1024, 1024], return_img=False)\n",
    "    pl.close()\n",
    "\n",
    "    # remove the mesh files if not needed\n",
    "    (output_path / f'{name_x[idx]}.obj').unlink(missing_ok=True)\n",
    "    (output_path / f'{name_x[idx]}.mtl').unlink(missing_ok=True)\n",
    "    (output_path / f'{name_x[idx]}--{name_y[idx]}.obj').unlink(missing_ok=True)\n",
    "    (output_path / f'{name_x[idx]}--{name_y[idx]}.mtl').unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0a874",
   "metadata": {},
   "source": [
    "## Benchmarking ground-truth correspondence\n",
    "\n",
    "Surprisingly, the ground-truth `p2p` has a ~4.5 geodesic error on the remeshed FAUST dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263872a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 5000]),\n",
       " tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0169, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0114],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0070, 0.0114],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0103]],\n",
       "        device='cuda:0'),\n",
       " tensor([0.0046, 0.0045, 0.0045, 0.0045, 0.0046, 0.0047, 0.0046, 0.0044],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metric.geodist import GeodesicDist_vectorized\n",
    "\n",
    "geodist = GeodesicDist_vectorized()\n",
    "err = geodist.geodesic_error(\n",
    "    dist_x=data['first']['dist'],\n",
    "    corr_x=data['first']['corr'],\n",
    "    corr_y=data['second']['corr'],\n",
    "    p2p=p2p,\n",
    ")\n",
    "err.shape, err, err.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb79c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), np.float32(0.0046353377), np.float32(0.0046353377))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metric.geodist import GeodesicDist\n",
    "\n",
    "geodist = GeodesicDist()\n",
    "err = geodist.calculate_geodesic_error(\n",
    "    dist_x=data['first']['dist'][0].cpu().numpy(),\n",
    "    corr_x=data['first']['corr'][0].cpu().numpy(),\n",
    "    corr_y=data['second']['corr'][0].cpu().numpy(),\n",
    "    p2p=p2p[0].cpu().numpy(),\n",
    ")\n",
    "err.shape, err, err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e384d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
